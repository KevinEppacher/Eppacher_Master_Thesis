@inproceedings{alamaRayFrontsOpenSetSemantic2025,
  title     = {RayFronts: Open-Set Semantic Ray Frontiers for Online Scene Understanding and Exploration},
  author    = {Alama, Omar and Bhattacharya, Avigyan and He, Haoyang and Kim, Seungchan and Qiu, Yuheng and Wang, Wenshan and Ho, Cherie and Keetha, Nikhil and Scherer, Sebastian},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year      = {2025},
  pages     = {5930--5937},
  doi       = {10.1109/IROS60139.2025.11245813}
}

@article{almadhounSurveyInspectingStructures2016,
  author  = {Almadhoun, Randa and Taha, Tarek and Seneviratne, Lakmal and Dias, Jorge and Cai, Guowei},
  title   = {A Survey on Inspecting Structures Using Robotic Systems},
  journal = {International Journal of Advanced Robotic Systems},
  year    = {2016},
  volume  = {13},
  number  = {6},
  pages   = {1729881416663664},
  doi     = {10.1177/1729881416663664},
  url     = {https://doi.org/10.1177/1729881416663664}
}

@inproceedings{bourgaultInformationBasedAdaptive2002,
  author    = {Bourgault, F. and Makarenko, A. A. and Williams, S. B. and Grocholsky, B. and Durrant-Whyte, H. F.},
  title     = {Information Based Adaptive Robotic Exploration},
  booktitle = {Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)},
  year      = {2002},
  pages     = {540--545},
  doi       = {10.1109/IRDS.2002.1041446}
}

@inproceedings{brohanRT2VisionLanguageActionModels2023,
  title     = {RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control},
  author    = {Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and Xu, Peng and Xiao, Ted and Xia, Fei and Wu, Jialin and Wohlhart, Paul and Welker, Stefan and Wahid, Ayzaan and Vuong, Quan and Vanhoucke, Vincent and Tran, Huong and Soricut, Radu and Singh, Anikait and Singh, Jaspiar and Sermanet, Pierre and Sanketi, Pannag R. and Salazar, Grecia and Ryoo, Michael S. and Reymann, Krista and Rao, Kanishka and Pertsch, Karl and Mordatch, Igor and Michalewski, Henryk and Lu, Yao and Levine, Sergey and Lee, Lisa and Lee, Tsang-Wei Edward and Leal, Isabel and Kuang, Yuheng and Kalashnikov, Dmitry and Julian, Ryan and Joshi, Nikhil J. and Irpan, Alex and Ichter, Brian and Hsu, Jasmine and Herzog, Alexander and Hausman, Karol and Gopalakrishnan, Keerthana and Fu, Chuyuan and Florence, Pete and Finn, Chelsea and Dubey, Kumar Avinava and Driess, Danny and Ding, Tianli and Choromanski, Krzysztof Marcin and Chen, Xi and Chebotar, Yevgen and Carbajal, Justice and Brown, Noah and Brohan, Anthony and Arenas, Montserrat Gonzalez and Han, Kehang},
  booktitle = {Proceedings of the Conference on Robot Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {229},
  pages     = {2165--2183},
  year      = {2023},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v229/zitkovich23a.html}
}

@inproceedings{brownLanguageModelsAre2020,
  author    = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  title     = {Language Models Are Few-Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {33},
  pages     = {1877--1901},
  year      = {2020},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
}

@inproceedings{buschOneMapFind2025,
  author    = {Busch, Finn Lukas and Homberger, Timon and Ortega-Peimbert, Jes{\'u}s and Yang, Quantao and Andersson, Olov},
  title     = {One Map to Find Them All: Real-Time Open-Vocabulary Mapping for Zero-Shot Multi-Object Navigation},
  booktitle = {Proc. IEEE Int. Conf. on Robotics and Automation (ICRA)},
  year      = {2025},
  pages     = {14835--14842},
  doi       = {10.1109/ICRA55743.2025.11128393}
}

@inproceedings{changMatterport3DLearningRGBD2017,
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niebner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  booktitle={2017 International Conference on 3D Vision (3DV)}, 
  title={Matterport3D: Learning from RGB-D Data in Indoor Environments}, 
  year={2017},
  volume={},
  number={},
  pages={667-676},
  keywords={Semantics;Cameras;Buildings;Surface reconstruction;Three-dimensional displays;Task analysis;Image reconstruction},
  doi={10.1109/3DV.2017.00081}
}


@inproceedings{chaplotObjectGoalNavigation2020,
  author    = {Chaplot, Devendra Singh and Gandhi, Dhiraj and Gupta, Abhinav and Salakhutdinov, Ruslan},
  title     = {Object Goal Navigation Using Goal-Oriented Semantic Exploration},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {33},
  pages     = {4247--4258},
  year      = {2020},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/2c75cf2681788adaca63aa95ae028b22-Paper.pdf}
}

@inproceedings{chengYOLOWorldRealTimeOpenVocabulary2024,
  title      = {YOLO-World: Real-Time Open-Vocabulary Object Detection},
  shorttitle = {YOLO-World},
  author     = {Cheng, Tianheng and Song, Lin and Ge, Yixiao and Liu, Wenyu and Wang, Xinggang and Shan, Ying},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2024},
  pages      = {16901--16911}
}

@inproceedings{chenHowNotTrain2023,
  author = {Chen, Junting and Li, Guohao and Kumar, Suryansh and Ghanem, Bernard and Yu, Fisher},
  title  = {How To Not Train Your Dragon: Training-free Embodied Object Goal Navigation with Semantic Frontiers},
  year   = {2023},
  month  = {07},
  doi    = {10.15607/RSS.2023.XIX.075}
}

@inproceedings{chertiReproducibleScalingLaws2022,
  title      = {Reproducible Scaling Laws for Contrastive Language-Image Learning},
  shorttitle = {Scaling Laws for CLIP},
  author     = {Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2023},
  pages      = {2818--2829}
}

@article{colledanchiseImplementationBehaviorTrees2021,
  author  = {Colledanchise, Michele and Natale, Lorenzo},
  title   = {On the Implementation of Behavior Trees in Robotics},
  journal = {IEEE Robotics and Automation Letters},
  volume  = {6},
  number  = {3},
  pages   = {5929--5936},
  year    = {2021},
  doi     = {10.1109/LRA.2021.3087442}
}

@book{corkeRoboticsVisionControl2023,
  author    = {Corke, Peter},
  title     = {Robotics, Vision and Control: Fundamental Algorithms in Python},
  date      = {2023},
  edition   = {3},
  series    = {Springer Tracts in Advanced Robotics},
  volume    = {146},
  publisher = {Springer International Publishing},
  location  = {Cham},
  doi       = {10.1007/978-3-031-06469-2},
  isbn      = {978-3-031-06468-5, 978-3-031-06469-2},
  url       = {https://link.springer.com/10.1007/978-3-031-06469-2}
}

@article{crouseImplementing2DRectangular2016,
  author  = {Crouse, David F.},
  title   = {On Implementing {2D} Rectangular Assignment Algorithms},
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  year    = {2016},
  volume  = {52},
  number  = {4},
  pages   = {1679--1696},
  doi     = {10.1109/TAES.2016.140952}
}

@inproceedings{daiScanNetRichlyannotated3D2017,
  title      = {ScanNet: Richly-Annotated 3D Reconstructions of Indoor Scenes},
  shorttitle = {ScanNet},
  author     = {Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Niessner, Matthias},
  booktitle  = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2017}
}

@misc{dedieuLearningNoisyORBayesian2023,
  author        = {Dedieu, Antoine and Zhou, Guangyao and George, Dileep and Lazaro-Gredilla, Miguel},
  title         = {Learning Noisy-{OR} {B}ayesian Networks with Max-Product Belief Propagation},
  year          = {2023},
  note          = {arXiv preprint},
  eprint        = {2302.00099},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},
  url           = {https://arxiv.org/abs/2302.00099}
}

@article{devlinBERTPretrainingDeep2018,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  journal      = {CoRR},
  volume       = {abs/1810.04805},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.04805},
  eprinttype    = {arXiv},
  eprint       = {1810.04805},
  timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{dorbalaCanEmbodiedAgent2024,
  author  = {Dorbala, Vishnu Sashank and Mullen, James F. and Manocha, Dinesh},
  title   = {Can an Embodied Agent Find Your ``Cat-shaped Mug''? {LLM}-Based Zero-Shot Object Navigation},
  journal = {IEEE Robotics and Automation Letters},
  year    = {2024},
  volume  = {9},
  number  = {5},
  pages   = {4083--4090},
  doi     = {10.1109/LRA.2023.3346800}
}

@article{hacinecipogluPoseInvariantPeople2020,
  title        = {Pose Invariant People Detection in Point Clouds for Mobile Robots},
  author       = {Hacinecipoglu, Akif and Konukseven, E. and Koku, Ahmet},
  journaltitle = {International Journal of Mechanical Engineering and Robotics Research},
  date         = {2020},
  volume       = {9},
  number       = {5},
  pages        = {709--715},
  doi          = {10.18178/ijmerr.9.5.709-715}
}

@inproceedings{gadreCoWsPastureBaselines2022,
  title        = {CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation},
  shorttitle   = {CoWs on Pasture},
  author       = {Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle   = {CVPR},
  date         = {2023},
  pages        = {23171--23181}
}

@article{gargSemanticsRoboticMapping2020,
  author  = {Garg, Sourav and Sünderhauf, Niko and Dayoub, Feras and Morrison, Douglas and Cosgun, Akansel and Carneiro, Gustavo and Wu, Qi and Chin, Tat-Jun and Reid, Ian and Gould, Stephen and Corke, Peter and Milford, Michael},
  title   = {Semantics for Robotic Mapping, Perception and Interaction: A Survey},
  journal = {Foundations and Trends in Robotics},
  year    = {2020},
  volume  = {8},
  number  = {1--2},
  pages   = {1--224},
  doi     = {10.1561/2300000059}
}

@misc{ghasemiComprehensiveSurveyReinforcement2025,
  title        = {A Comprehensive Survey of Reinforcement Learning: From Algorithms to Practical Challenges},
  author       = {Ghasemi, Majid and Moosavi, Amir Hossein and Ebrahimi, Dariush},
  year         = {2025},
  note         = {arXiv preprint arXiv:2411.18892},
  eprint       = {2411.18892},
  archivePrefix= {arXiv},
  primaryClass = {cs.AI},
  url          = {https://arxiv.org/abs/2411.18892}
}

@inproceedings{guConceptGraphsOpenVocabulary3D2023,
  author    = {Gu, Qiao and Kuwajerwala, Ali and Morin, Sacha and Jatavallabhula, Krishna Murthy and Sen, Bipasha and Agarwal, Aditya and Rivera, Corban and Paul, William and Ellis, Kirsty and Chellappa, Rama and Gan, Chuang and de Melo, Celso Miguel and Tenenbaum, Joshua B. and Torralba, Antonio and Shkurti, Florian and Paull, Liam},
  title     = {ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2024},
  pages     = {5021--5028},
  doi       = {10.1109/ICRA57147.2024.10610243}
}

@inproceedings{guptaLVISDatasetLarge2019,
  title      = {LVIS: A Dataset for Large Vocabulary Instance Segmentation},
  shorttitle = {LVIS},
  author     = {Gupta, Agrim and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2019}
}

@article{hacinecipogluPoseInvariantPeople2020,
  author  = {Hacinecipoglu, Akif and Konukseven, E. and Koku, Ahmet},
  title   = {Pose Invariant People Detection in Point Clouds for Mobile Robots},
  journal = {International Journal of Mechanical Engineering and Robotics Research},
  year    = {2020},
  pages   = {709--715},
  doi     = {10.18178/ijmerr.9.5.709-715}
}

@inproceedings{hanFetchBenchSimulationBenchmark2024,
  title     = {FetchBench: A Simulation Benchmark for Robot Fetching},
  author    = {Han, Beining and Parakh, Meenal and Geng, Derek and Defay, Jack A. and Gan, Luyang and Deng, Jia},
  booktitle = {Proceedings of the Conference on Robot Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {270},
  pages     = {3053--3071},
  year      = {2025},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v270/han25a.html}
}

@inproceedings{heMaskRCNN2018,
  author    = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  title     = {Mask {R-CNN}},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year      = {2017}
}

@inproceedings{huangVisualLanguageMaps2023,
  author    = {Huang, Chenguang and Mees, Oier and Zeng, Andy and Burgard, Wolfram},
  title     = {Visual Language Maps for Robot Navigation},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2023},
  pages     = {10608--10615},
  doi       = {10.1109/ICRA48891.2023.10160969}
}

@inproceedings{jatavallabhulaConceptFusionOpensetMultimodal2023,
  author    = {Jatavallabhula, Krishna Murthy and Kuwajerwala, Alihusein and Gu, Qiao and Omama, Mohd and Chen, Tao and Maalouf, Alaa and Li, Shuang and Iyer, Ganesh and Saryazdi, Soroush and Keetha, Nikhil and Tewari, Ayush and Tenenbaum, Joshua B. and de Melo, Celso Miguel and Krishna, Madhava and Paull, Liam and Shkurti, Florian and Torralba, Antonio},
  title     = {ConceptFusion: Open-set Multimodal 3D Mapping},
  booktitle = {Proceedings of Robotics: Science and Systems (RSS)},
  year      = {2023}
}

@misc{jiangCLIPDINOVisual2024,
  author        = {Jiang, Dongsheng and Liu, Yuchen and Liu, Songlin and Zhao, Jin'e and Zhang, Hao and Gao, Zhen and Zhang, Xiaopeng and Li, Jin and Xiong, Hongkai},
  title         = {From {CLIP} to {DINO}: Visual Encoders Shout in Multi-modal Large Language Models},
  year          = {2024},
  note          = {arXiv preprint},
  eprint        = {2310.08825},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CV},
  doi           = {10.48550/arXiv.2310.08825},
  url           = {https://arxiv.org/abs/2310.08825}
}

@article{jiangDualMapOnlineOpenVocabulary2025,
  author  = {Jiang, Jiajun and Zhu, Yiming and Wu, Zirui and Song, Jie},
  title   = {DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes},
  journal = {IEEE Robotics and Automation Letters},
  year    = {2025},
  volume  = {10},
  number  = {12},
  pages   = {12612--12619},
  doi     = {10.1109/LRA.2025.3621942}
}

@article{kabirEnhancedRobotMotionBlockAStar2024,
  author  = {Kabir, Raihan and Watanobe, Yutaka and Islam, Md Rashedul and Naruse, Keitaro},
  title   = {Enhanced Robot Motion Block of A-Star Algorithm for Robotic Path Planning},
  journal = {Sensors},
  year    = {2024},
  volume  = {24},
  number  = {5},
  pages   = {1422},
  doi     = {10.3390/s24051422}
}

@article{kansoSemanticSLAMSurvey2025,
  author  = {Kanso, Houssein and Singh, Abhilasha and El Zarif, Etaf and Almohammed, Nooruldeen and Mounsef, Jinane and Maalouf, Noel and Arain, Bilal},
  title   = {Semantic SLAM: A Comprehensive Survey of Methods and Applications},
  journal = {Intelligent Systems with Applications},
  year    = {2025},
  volume  = {28},
  pages   = {200591},
  doi     = {10.1016/j.iswa.2025.200591}
}

@inproceedings{kerrLERFICCV2023,
  title      = {LERF: Language Embedded Radiance Fields},
  shorttitle = {LERF},
  author     = {Kerr, Justin and Kim, Chung Min and Goldberg, Ken and Kanazawa, Angjoo and Tancik, Matthew},
  booktitle  = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  eventtitle = {ICCV},
  date       = {2023-10},
  pages      = {19729--19739}
}

@inproceedings{kirillovSegmentAnything2023,
  author    = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  title     = {Segment Anything},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      = {2023},
  month     = {10},
  pages     = {4015--4026}
}

@inproceedings{koenigDesignUseParadigms2004,
  author    = {Koenig, N. and Howard, A.},
  title     = {Design and Use Paradigms for Gazebo, an Open-Source Multi-Robot Simulator},
  booktitle = {2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year      = {2004},
  pages     = {2149--2154},
  doi       = {10.1109/IROS.2004.1389727},
  volume    = {3}
}

@inproceedings{kuJoint3DProposal2018,
  author    = {Ku, Jason and Mozifian, Melissa and Lee, Jungwook and Harakeh, Ali and Waslander, Steven L.},
  title     = {Joint {3D} Proposal Generation and Object Detection from View Aggregation},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year      = {2018},
  pages     = {1--8},
  doi       = {10.1109/IROS.2018.8594049}
}

@misc{leeOptimizingROS22025,
    author       = {Lee, Sanghoon and Kim, Taehun and Chae, Jiyeong and Park, Kyung-Joon},
    title        = {Optimizing {ROS} 2 Communication for Wireless Robotic Systems},
    year         = {2025},
    eprint       = {2508.11366},
    archivePrefix= {arXiv},
    primaryClass = {cs.NI},
    doi          = {10.48550/arXiv.2508.11366},
    url          = {https://arxiv.org/abs/2508.11366}
}

@inproceedings{liBLIP2BootstrappingLanguageImage2023,
    author    = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
    title     = {{BLIP-2}: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
    booktitle = {Proceedings of the 40th International Conference on Machine Learning},
    series    = {Proceedings of Machine Learning Research},
    volume    = {202},
    pages     = {19730--19742},
    year      = {2023},
    publisher = {PMLR},
    url       = {https://proceedings.mlr.press/v202/li23q.html}
}

@inproceedings{liGroundedLanguageImagePretraining2022,
  title      = {Grounded Language-Image Pre-Training},
  shorttitle = {GLIP},
  author     = {Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and Chang, Kai-Wei and Gao, Jianfeng},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2022},
  pages      = {10965--10975}
}

@misc{liLanguagedrivenSemanticSegmentation2022,
    author        = {Li, Boyi and Weinberger, Kilian Q. and Belongie, Serge and Koltun, Vladlen and Ranftl, Ren{\'e}},
    title         = {Language-driven Semantic Segmentation},
    year          = {2022},
    eprint        = {2201.03546},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.2201.03546},
    url           = {https://arxiv.org/abs/2201.03546}
}

@misc{liLAVISLibraryLanguageVision2022,
    author        = {Li, Dongxu and Li, Junnan and Le, Hung and Wang, Guangsen and Savarese, Silvio and Hoi, Steven C. H.},
    title         = {{LAVIS}: A Library for Language-Vision Intelligence},
    year          = {2022},
    eprint        = {2209.09019},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.2209.09019},
    url           = {https://arxiv.org/abs/2209.09019}
}

@inproceedings{linMicrosoftCOCOCommon2015,
    author    = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C. Lawrence},
    title     = {Microsoft COCO: Common Objects in Context},
    booktitle = {Computer Vision -- ECCV 2014},
    year      = {2014},
    publisher = {Springer International Publishing},
    address   = {Cham},
    pages     = {740--755},
    doi       = {10.1007/978-3-319-10602-1_48}
}

@book{liu3DPointCloud2021,
  title     = {3D Point Cloud Analysis},
  subtitle  = {Deep Learning, and Explainable Machine Learning Methods},
  author    = {Liu, Shan and Zhang, Min and Kadam, Pranav and Kuo, C.-C. Jay},
  publisher = {Springer},
  location  = {Cham},
  date      = {2021},
  doi       = {10.1007/978-3-030-89180-0},
  isbn      = {978-3-030-89179-4}
}

@misc{liuGroundingDINOMarrying2024,
    author        = {Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Jiang, Qing and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and Zhang, Lei},
    title         = {Grounding {DINO}: Marrying {DINO} with Grounded Pre-Training for Open-Set Object Detection},
    year          = {2024},
    eprint        = {2303.05499},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.2303.05499},
    url           = {https://arxiv.org/abs/2303.05499}
}

@article{lluviaActiveMappingRobot2021,
    author       = {Lluvia, Iker and Lazkano, Elena and Ansuategi, Ander},
    title        = {Active Mapping and Robot Exploration: A Survey},
    journal      = {Sensors},
    year         = {2021},
    volume       = {21},
    number       = {7},
    pages        = {2445},
    doi          = {10.3390/s21072445},
    issn         = {1424-8220},
    url          = {https://www.mdpi.com/1424-8220/21/7/2445}
}

@article{macenskiDesksROSMaintainers2023,
    author  = {Macenski, Steve and Moore, Tom and Lu, David V. and Merzlyakov, Alexey and Ferguson, Michael},
    title   = {From the desks of ROS maintainers: A survey of modern \& capable mobile robotics algorithms in the robot operating system 2},
    journal = {Robotics and Autonomous Systems},
    year    = {2023},
    volume  = {168},
    pages   = {104493},
    issn    = {0921-8890},
    doi     = {10.1016/j.robot.2023.104493},
    url     = {https://www.sciencedirect.com/science/article/pii/S092188902300132X}
}

@article{macenskiImpactROS22023,
    author  = {Macenski, Steve and Soragna, Alberto and Carroll, Michael and Ge, Zhenpeng},
    title   = {Impact of {ROS} 2 Node Composition in Robotic Systems},
    journal = {IEEE Robotics and Automation Letters},
    year    = {2023},
    volume  = {8},
    number  = {7},
    pages   = {3996--4003},
    doi     = {10.1109/LRA.2023.3279614}
}

@article{macenskiSLAMToolboxSLAM2021,
    author  = {Macenski, Steve and Jambrecic, Ivona},
    title   = {{SLAM} Toolbox: {SLAM} for the Dynamic World},
    journal = {Journal of Open Source Software},
    year    = {2021},
    volume  = {6},
    pages   = {2783},
    doi     = {10.21105/joss.02783}
}

@article{maggioClioRealtimeTaskDriven2024,
    author  = {Maggio, Dominic and Chang, Yun and Hughes, Nathan and Trang, Matthew and Griffith, Dan and Dougherty, Carlyn and Cristofalo, Eric and Schmid, Lukas and Carlone, Luca},
    title   = {Clio: Real-Time Task-Driven Open-Set 3D Scene Graphs},
    journal = {IEEE Robotics and Automation Letters},
    year    = {2024},
    volume  = {9},
    number  = {10},
    pages   = {8921--8928},
    doi     = {10.1109/LRA.2024.3451395}
}

@inproceedings{majumdarZSONZeroShotObjectGoal2023,
    author    = {Majumdar, Arjun and Aggarwal, Gunjan and Devnani, Bhavika and Hoffman, Judy and Batra, Dhruv},
    title     = {{ZSON}: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings},
    booktitle = {Advances in Neural Information Processing Systems},
    year      = {2022},
    volume    = {35},
    pages     = {32340--32352},
    publisher = {Curran Associates, Inc.},
    url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/d0b8f0c8f79d3a621af945cafb669f4b-Paper-Conference.pdf}
}

@misc{makoviychukIsaacGymHigh2021,
    author        = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and State, Gavriel},
    title         = {Isaac Gym: High Performance GPU-Based Physics Simulation For Robot Learning},
    year          = {2021},
    eprint        = {2108.10470},
    archivePrefix = {arXiv},
    doi           = {10.48550/arXiv.2108.10470},
    url           = {https://arxiv.org/abs/2108.10470}
}

@misc{meierCARLADroneMonocular2024,
    author        = {Meier, Johannes and Scalerandi, Luca and Dhaouadi, Oussema and Kaiser, Jacques and Araslanov, Nikita and Cremers, Daniel},
    title         = {{CARLA} Drone: Monocular 3D Object Detection from a Different Perspective},
    year          = {2024},
    eprint        = {2408.11958},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.2408.11958},
    url           = {https://arxiv.org/abs/2408.11958}
}

@article{miaoFrontierReviewSemantic2025,
    author  = {Miao, Le and Liu, Wen and Deng, Zhongliang},
    title   = {A Frontier Review of Semantic {SLAM} Technologies Applied to the Open World},
    journal = {Sensors},
    year    = {2025},
    volume  = {25},
    number  = {16},
    pages   = {4994},
    doi     = {10.3390/s25164994},
    issn    = {1424-8220},
    url     = {https://www.mdpi.com/1424-8220/25/16/4994}
}

@inproceedings{mildenhallNeRFRepresentingScenes2020,
  author    = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  title     = {{NeRF}: Representing Scenes as Neural Radiance Fields for View Synthesis},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2020},
  pages     = {405--421}
}

@misc{mindererScalingOpenVocabularyObject2024,
    author        = {Minderer, Matthias and Gritsenko, Alexey and Houlsby, Neil},
    title         = {Scaling Open-Vocabulary Object Detection},
    year          = {2024},
    eprint        = {2306.09683},
    archivePrefix = {arXiv},
    doi           = {10.48550/arXiv.2306.09683},
    url           = {https://arxiv.org/abs/2306.09683}
}

@misc{oquabDINOv2LearningRobust2024,
    author        = {Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Assran, Mahmoud and Ballas, Nicolas and Galuba, Wojciech and Howes, Russell and Huang, Po-Yao and Li, Shang-Wen and Misra, Ishan and Rabbat, Michael and Sharma, Vasu and Synnaeve, Gabriel and Xu, Hu and Jegou, Herv{\'e} and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
    title         = {{DINOv2}: Learning Robust Visual Features without Supervision},
    year          = {2024},
    eprint        = {2304.07193},
    archivePrefix = {arXiv},
    doi           = {10.48550/arXiv.2304.07193},
    url           = {https://arxiv.org/abs/2304.07193}
}

@book{PDFRobustStatistics,
    author    = {Hampel, Frank and Ronchetti, Elvezio and Rousseeuw, Peter and Stahel, Werner},
    title     = {Robust Statistics: The Approach Based on Influence Functions},
    year      = {1986},
    doi       = {10.1002/9781118186435},
    isbn      = {9780471735779}
}

@misc{pengPIGEONVLMDrivenObject2025,
    author        = {Peng, Cheng and Zhang, Zhenzhe and Chi, Cheng and Wei, Xiaobao and Zhang, Yanhao and Wang, Heng and Wang, Pengwei and Wang, Zhongyuan and Liu, Jing and Zhang, Shanghang},
    title         = {{PIGEON}: {VLM}-Driven Object Navigation via Points of Interest Selection},
    year          = {2025},
    eprint        = {2511.13207},
    archivePrefix = {arXiv},
    primaryClass  = {cs.RO},
    doi           = {10.48550/arXiv.2511.13207},
    url           = {https://arxiv.org/abs/2511.13207}
}

@article{ProbabilisticReasoningIntelligent,
    author  = {Andersen, Stig},
    title   = {Judea Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.},
    journal = {Artif. Intell.},
    year    = {1991},
    volume  = {48},
    pages   = {117--124},
    doi     = {10.1016/0004-3702(91)90084-W}
}

@misc{puigHabitat30CoHabitat2023,
    author        = {Puig, Xavier and Undersander, Eric and Szot, Andrew and Cote, Mikael Dallaire and Yang, Tsung-Yen and Partsey, Ruslan and Desai, Ruta and Clegg, Alexander William and Hlavac, Michal and Min, So Yeon and Vondru{\v{s}}, Vladim{\'\i}r and Gervet, Theophile and Berges, Vincent-Pierre and Turner, John M. and Maksymets, Oleksandr and Kira, Zsolt and Kalakrishnan, Mrinal and Malik, Jitendra and Chaplot, Devendra Singh and Jain, Unnat and Batra, Dhruv and Rai, Akshara and Mottaghi, Roozbeh},
    title         = {Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots},
    year          = {2023},
    eprint        = {2310.13724},
    archivePrefix = {arXiv},
    primaryClass  = {cs.HC},
    doi           = {10.48550/arXiv.2310.13724},
    url           = {https://arxiv.org/abs/2310.13724}
}

@inproceedings{putzMoveBaseFlex2018,
    author    = {P{\"u}tz, Sebastian and Santos Sim{\'o}n, Jorge and Hertzberg, Joachim},
    title     = {Move Base Flex A Highly Flexible Navigation Framework for Mobile Robots},
    booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    year      = {2018},
    pages     = {3416--3421},
    doi       = {10.1109/IROS.2018.8593829}
}

@inproceedings{qiuLearningGeneralizableFeature2024,
    author    = {Qiu, Ri-Zhao and Hu, Yafei and Song, Yuchen and Yang, Ge and Fu, Yang and Ye, Jianglong and Mu, Jiteng and Yang, Ruihan and Atanasov, Nikolay and Scherer, Sebastian and Wang, Xiaolong},
    title     = {Learning Generalizable Feature Fields for Mobile Manipulation},
    booktitle = {2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    year      = {2025},
    pages     = {20952--20959},
    doi       = {10.1109/IROS60139.2025.11246780}
}

@article{quinApproachesEfficientlyDetecting2021,
    author  = {Quin, Phillip and Nguyen, Dac and Vu, Thanh and Alempijevic, Alen and Paul, Gavin},
    title   = {Approaches for Efficiently Detecting Frontier Cells in Robotics Exploration},
    journal = {Frontiers in Robotics and AI},
    year    = {2021},
    volume  = {8},
    pages   = {616470},
    doi     = {10.3389/frobt.2021.616470}
}

@inproceedings{radfordLearningTransferableVisual2021,
    author    = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
    title     = {Learning Transferable Visual Models From Natural Language Supervision},
    booktitle = {Proc. Int. Conf. on Machine Learning (ICML)},
    series    = {Proceedings of Machine Learning Research},
    volume    = {139},
    pages     = {8748--8763},
    year      = {2021},
    publisher = {PMLR},
    url       = {https://proceedings.mlr.press/v139/radford21a.html}
}

@misc{ramakrishnanHabitatMatterport3DDataset2021,
    author        = {Ramakrishnan, Santhosh K. and Gokaslan, Aaron and Wijmans, Erik and Maksymets, Oleksandr and Clegg, Alex and Turner, John and Undersander, Eric and Galuba, Wojciech and Westbury, Andrew and Chang, Angel X. and Savva, Manolis and Zhao, Yili and Batra, Dhruv},
    title         = {Habitat-Matterport 3D Dataset ({HM3D}): 1000 Large-scale 3D Environments for Embodied {AI}},
    year          = {2021},
    eprint        = {2109.08238},
    archivePrefix = {arXiv},
    doi           = {10.48550/arXiv.2109.08238},
    url           = {https://arxiv.org/abs/2109.08238}
}

@inproceedings{ramakrishnanPONIPotentialFunctions2022,
  title      = {PONI: Potential Functions for ObjectGoal Navigation With Interaction-Free Learning},
  shorttitle = {PONI},
  author     = {Ramakrishnan, Santhosh Kumar and Chaplot, Devendra Singh and Al-Halah, Ziad and Malik, Jitendra and Grauman, Kristen},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2022},
  pages      = {18890--18900}
}

@inproceedings{ramrakhyaPIRLNavPretrainingImitation2023,
  title      = {PIRLNav: Pretraining With Imitation and {RL} Finetuning for ObjectNav},
  shorttitle = {PIRLNav},
  author     = {Ramrakhya, Ram and Batra, Dhruv and Wijmans, Erik and Das, Abhishek},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2023},
  pages      = {17896--17906}
}

@inproceedings{ranzingerAMRADIOAgglomerativeVision2024,
  title      = {AM-RADIO: Agglomerative Vision Foundation Model Reduce All Domains Into One},
  shorttitle = {AM-RADIO},
  author     = {Ranzinger, Mike and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  eventtitle = {CVPR},
  date       = {2024},
  pages      = {12490--12500}
}

@misc{raviSAM2Segment2024,
    author        = {Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
    title         = {{SAM} 2: Segment Anything in Images and Videos},
    year          = {2024},
    eprint        = {2408.00714},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.2408.00714},
    url           = {https://arxiv.org/abs/2408.00714}
}

@inproceedings{redmonYouOnlyLook2016,
    author    = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
    title     = {You Only Look Once: Unified, Real-Time Object Detection},
    booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2016},
    pages     = {779--788},
    doi       = {10.1109/CVPR.2016.91}
}

@article{RoboticExplorationUsing,
    author  = {Suresh, Aamodh and Nieto-Granda, Carlos and Mart{\'\i}nez, Sonia},
    title   = {Robotic Exploration Using Generalized Behavioral Entropy},
    journal = {IEEE Robotics and Automation Letters},
    year    = {2024},
    volume  = {9},
    number  = {9},
    pages   = {8011--8018},
    doi     = {10.1109/LRA.2024.3433207}
}

@inproceedings{ruanTaxonomySemanticInformation2022,
    author    = {Ruan, Tianshu and Wang, Hao and Stolkin, Rustam and Chiou, Manolis},
    title     = {A Taxonomy of Semantic Information in Robot-Assisted Disaster Response},
    booktitle = {2022 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
    year      = {2022},
    pages     = {285--292},
    doi       = {10.1109/SSRR56537.2022.10018727}
}

@article{rusu3DPointCloud2008,
  title = {Towards {{3D Point}} Cloud Based Object Maps for Household Environments},
  author = {Rusu, Radu Bogdan and Marton, Zoltan Csaba and Blodow, Nico and Dolha, Mihai and Beetz, Michael},
  date = {2008-11-30},
  journaltitle = {Robotics and Autonomous Systems},
  shortjournal = {Robotics and Autonomous Systems},
  series = {Semantic {{Knowledge}} in {{Robotics}}},
  volume = {56},
  number = {11},
  pages = {927--941},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2008.08.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0921889008001140},
  urldate = {2026-01-17},
  abstract = {This article investigates the problem of acquiring 3D object maps of indoor household environments, in particular kitchens. The objects modeled in these maps include cupboards, tables, drawers and shelves, which are of particular importance for a household robotic assistant. Our mapping approach is based on PCD (point cloud data) representations. Sophisticated interpretation methods operating on these representations eliminate noise and resample the data without deleting the important details, and interpret the improved point clouds in terms of rectangular planes and 3D geometric shapes. We detail the steps of our mapping approach and explain the key techniques that make it work. The novel techniques include statistical analysis, persistent histogram features estimation that allows for a consistent registration, resampling with additional robust fitting techniques, and segmentation of the environment into meaningful regions.},
  keywords = {Environment object model,Geometrical reasoning,Point cloud data},
  file = {/home/kevin/snap/zotero-snap/common/Zotero/storage/ABMWKS56/S0921889008001140.html}
}

@online{salimpourSimtoRealTransferMobile2025,
  title        = {Sim-to-Real Transfer for Mobile Robots with Reinforcement Learning: From {NVIDIA} Isaac Sim to Gazebo and Real {ROS} 2 Robots},
  shorttitle   = {Sim-to-Real Transfer for Mobile Robots},
  author       = {Salimpour, Sahar and Pe{\~n}a-Queralta, Jorge and Paez-Granados, Diego and Heikkonen, Jukka and Westerlund, Tomi},
  date         = {2025},
  eprint       = {2501.02902},
  eprinttype  = {arXiv},
  eprintclass = {cs.RO},
  doi          = {10.48550/arXiv.2501.02902},
  url          = {https://arxiv.org/abs/2501.02902},
  urldate      = {2026-01-14}
}

@online{sapkotaUltralyticsYOLOEvolution2025,
  title        = {Ultralytics {YOLO} Evolution: An Overview of {YOLO26}, {YOLO11}, {YOLOv8} and {YOLOv5} Object Detectors for Computer Vision and Pattern Recognition},
  shorttitle   = {Ultralytics {YOLO} Evolution},
  author       = {Sapkota, Ranjan and Karkee, Manoj},
  date         = {2025},
  eprint       = {2510.09653},
  eprinttype   = {arXiv},
  eprintclass  = {cs.CV},
  doi          = {10.48550/arXiv.2510.09653},
  url          = {https://arxiv.org/abs/2510.09653},
  urldate      = {2026-01-14}
}

@inproceedings{savvaHabitatPlatformEmbodied2019,
    author    = {Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and Parikh, Devi and Batra, Dhruv},
    title     = {Habitat: A Platform for Embodied AI Research},
    booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2019},
    pages     = {9338--9346},
    doi       = {10.1109/ICCV.2019.00943}
}

@misc{schwaigerOTASOpenvocabularyToken2025,
    author        = {Schwaiger, Simon and Thalhammer, Stefan and W{\"o}ber, Wilfried and Steinbauer-Wagner, Gerald},
    title         = {{OTAS}: Open-vocabulary Token Alignment for Outdoor Segmentation},
    year          = {2025},
    eprint        = {2507.08851},
    archivePrefix = {arXiv},
    primaryClass  = {cs.RO},
    doi           = {10.48550/arXiv.2507.08851},
    url           = {https://arxiv.org/abs/2507.08851}
}

@online{schwaigerUGVCBRNUnmannedGround2024,
  title        = {{UGV-CBRN}: An Unmanned Ground Vehicle for Chemical, Biological, Radiological, and Nuclear Disaster Response},
  shorttitle   = {UGV-CBRN},
  author       = {Schwaiger, Simon and Muster, Lucas and Novotny, Georg and Schebek, Michael and W{\"o}ber, Wilfried and Thalhammer, Stefan and B{\"o}hm, Christoph},
  date         = {2024},
  eprint       = {2406.14385},
  eprinttype  = {arXiv},
  eprintclass = {cs.RO},
  doi          = {10.48550/arXiv.2406.14385},
  url          = {https://arxiv.org/abs/2406.14385},
  urldate     = {2026-01-02}
}

@misc{sharirImageWorth16x162021,
    author        = {Sharir, Gilad and Noy, Asaf and Zelnik-Manor, Lihi},
    title         = {An Image Is Worth 16x16 Words, What Is a Video Worth?},
    year          = {2021},
    eprint        = {2103.13915},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.2103.13915},
    url           = {https://arxiv.org/abs/2103.13915}
}

@misc{straubReplicaDatasetDigital2019,
    author        = {Straub, Julian and Whelan, Thomas and Ma, Lingni and Chen, Yufan and Wijmans, Erik and Green, Simon and Engel, Jakob J. and Mur-Artal, Raul and Ren, Carl and Verma, Shobhit and Clarkson, Anton and Yan, Mingfei and Budge, Brian and Yan, Yajie and Pan, Xiaqing and Yon, June and Zou, Yuyang and Leon, Kimberly and Carter, Nigel and Briales, Jesus and Gillingham, Tyler and Mueggler, Elias and Pesqueira, Luis and Savva, Manolis and Batra, Dhruv and Strasdat, Hauke M. and De Nardi, Renzo and Goesele, Michael and Lovegrove, Steven and Newcombe, Richard},
    title         = {The Replica Dataset: A Digital Replica of Indoor Spaces},
    year          = {2019},
    eprint        = {1906.05797},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    doi           = {10.48550/arXiv.1906.05797},
    url           = {https://arxiv.org/abs/1906.05797}
}

@inproceedings{tellaroliFrontierBasedExplorationMultiRobot2024,
    author    = {Tellaroli, Mauro and Luperto, Matteo and Antonazzi, Michele and Basilico, Nicola},
    title     = {Frontier-Based Exploration for Multi-Robot Rendezvous in Communication-Restricted Unknown Environments},
    booktitle = {2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
    year      = {2024},
    pages     = {5807--5812},
    doi       = {10.1109/IROS58592.2024.10801321}
}

@online{thomasPolicyGradientMethods2017,
  title        = {Policy Gradient Methods for Reinforcement Learning with Function Approximation and Action-Dependent Baselines},
  shorttitle   = {Policy Gradient Methods},
  author       = {Thomas, Philip S. and Brunskill, Emma},
  date         = {2017},
  eprint       = {1706.06643},
  eprinttype  = {arXiv},
  eprintclass = {cs.AI},
  doi          = {10.48550/arXiv.1706.06643},
  url          = {https://arxiv.org/abs/1706.06643},
  urldate     = {2026-01-02}
}

@book{thrunProbabilisticRobotics2006,
    author    = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
    title     = {Probabilistic Robotics},
    year      = {2006},
    publisher = {MIT Press},
    address   = {Cambridge, MA, USA},
    isbn      = {978-0-262-20162-9}
}

@misc{topiwalaFrontierBasedExploration2018,
    author       = {Topiwala, Anirudh and Inani, Pranav and Kathpal, Abhishek},
    title        = {Frontier Based Exploration for Autonomous Robot},
    year         = {2018},
    eprint       = {1806.03581},
    archivePrefix= {arXiv},
    primaryClass = {cs.RO},
    doi          = {10.48550/arXiv.1806.03581},
    url          = {https://arxiv.org/abs/1806.03581}
}

@inproceedings{vaswaniAttentionAllYou2023,
  title = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  date = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}
}

@online{wangYOLOERealTimeSeeing2025,
  title        = {YOLOE: Real-Time Seeing Anything},
  shorttitle   = {YOLOE},
  author       = {Wang, Ao and Liu, Lihao and Chen, Hui and Lin, Zijia and Han, Jungong and Ding, Guiguang},
  date         = {2025},
  eprint       = {2503.07465},
  eprinttype  = {arXiv},
  eprintclass = {cs.CV},
  url          = {https://arxiv.org/abs/2503.07465},
  urldate     = {2026-01-02}
}

@inproceedings{wangYOLOv7TrainableBagoffreebies2022,
    author    = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
    title     = {{YOLOv7}: {Trainable} Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors},
    booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2023},
    pages     = {7464--7475},
    doi       = {10.1109/CVPR52729.2023.00721}
}

@online{westphalGeneralizedInformationBottleneck2025,
  title = {A {{Generalized Information Bottleneck Theory}} of {{Deep Learning}}},
  author = {Westphal, Charles and Hailes, Stephen and Musolesi, Mirco},
  date = {2025-10-14},
  eprint = {2509.26327},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2509.26327},
  url = {http://arxiv.org/abs/2509.26327},
  urldate = {2026-01-10},
  abstract = {The Information Bottleneck (IB) principle offers a compelling theoretical framework to understand how neural networks (NNs) learn. However, its practical utility has been constrained by unresolved theoretical ambiguities and significant challenges in accurate estimation. In this paper, we present a \textbackslash textit\{Generalized Information Bottleneck (GIB)\} framework that reformulates the original IB principle through the lens of synergy, i.e., the information obtainable only through joint processing of features. We provide theoretical and empirical evidence demonstrating that synergistic functions achieve superior generalization compared to their non-synergistic counterparts. Building on these foundations we re-formulate the IB using a computable definition of synergy based on the average interaction information (II) of each feature with those remaining. We demonstrate that the original IB objective is upper bounded by our GIB in the case of perfect estimation, ensuring compatibility with existing IB theory while addressing its limitations. Our experimental results demonstrate that GIB consistently exhibits compression phases across a wide range of architectures (including those with \textbackslash textit\{ReLU\} activations where the standard IB fails), while yielding interpretable dynamics in both CNNs and Transformers and aligning more closely with our understanding of adversarial robustness.},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning},
  file = {/home/kevin/snap/zotero-snap/common/Zotero/storage/DW6A3LBC/Westphal et al. - 2025 - A Generalized Information Bottleneck Theory of Deep Learning.pdf;/home/kevin/snap/zotero-snap/common/Zotero/storage/C97VB9RP/2509.html}
}

@inproceedings{xiaGibsonEnvRealWorld2018,
  title            = {Gibson Env: Real-World Perception for Embodied Agents},
  shorttitle       = {Gibson Env},
  author           = {Xia, Fei and Zamir, Amir R. and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
  booktitle        = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  eventtitle       = {CVPR},
  date             = {2018-06}
}

@inproceedings{yamauchiFrontierbasedApproachAutonomous1997,
  title            = {A Frontier-Based Approach for Autonomous Exploration},
  author           = {Yamauchi, Brian},
  booktitle        = {Proceedings of the IEEE International Symposium},
  booktitleaddon   = {Computational Intelligence in Robotics and Automation},
  eventtitle       = {CIRA},
  date             = {1997-07},
  pages            = {146--151},
  doi              = {10.1109/CIRA.1997.613851},
  url              = {https://ieeexplore.ieee.org/document/613851},
  urldate          = {2026-01-14}
}

@inproceedings{yamazakiOpenFusionRealtimeOpenVocabulary2023,
    author    = {Yamazaki, Kashu and Hanyu, Taisei and Vo, Khoa and Pham, Thang and Tran, Minh and Doretto, Gianfranco and Nguyen, Anh and Le, Ngan},
    title     = {{Open-Fusion}: {Real-time Open-Vocabulary 3D Mapping} and {Queryable Scene Representation}},
    booktitle = {2024 IEEE International Conference on Robotics and Automation (ICRA)},
    year      = {2024},
    pages     = {9411--9417},
    doi       = {10.1109/ICRA57147.2024.10610193}
}

@inproceedings{yokoyamaVLFMVisionLanguageFrontier2023,
    author    = {Yokoyama, Naoki and Ha, Sehoon and Batra, Dhruv and Wang, Jiuguang and Bucher, Bernadette},
    title     = {{VLFM}: {Vision-Language Frontier Maps} for {Zero-Shot Semantic Navigation}},
    booktitle = {2024 IEEE International Conference on Robotics and Automation (ICRA)},
    year      = {2024},
    pages     = {42--48},
    doi       = {10.1109/ICRA57147.2024.10610712}
}

@online{zakkaMuJoCoPlayground2025,
  title = {{{MuJoCo Playground}}},
  author = {Zakka, Kevin and Tabanpour, Baruch and Liao, Qiayuan and Haiderbhai, Mustafa and Holt, Samuel and Luo, Jing Yuan and Allshire, Arthur and Frey, Erik and Sreenath, Koushil and Kahrs, Lueder A. and Sferrazza, Carmelo and Tassa, Yuval and Abbeel, Pieter},
  date = {2025-02-12},
  eprint = {2502.08844},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2502.08844},
  url = {http://arxiv.org/abs/2502.08844},
  urldate = {2026-01-19},
  abstract = {We introduce MuJoCo Playground, a fully open-source framework for robot learning built with MJX, with the express goal of streamlining simulation, training, and sim-to-real transfer onto robots. With a simple "pip install playground", researchers can train policies in minutes on a single GPU. Playground supports diverse robotic platforms, including quadrupeds, humanoids, dexterous hands, and robotic arms, enabling zero-shot sim-to-real transfer from both state and pixel inputs. This is achieved through an integrated stack comprising a physics engine, batch renderer, and training environments. Along with video results, the entire framework is freely available at playground.mujoco.org},
  pubstate = {prepublished},
  keywords = {Computer Science - Robotics},
  file = {/home/kevin/snap/zotero-snap/common/Zotero/storage/6TCX9KQP/Zakka et al. - 2025 - MuJoCo Playground.pdf;/home/kevin/snap/zotero-snap/common/Zotero/storage/PVIFQGS6/2502.html}
}

@inproceedings{zareianOpenVocabularyObjectDetection2021,
    author    = {Zareian, Alireza and Dela Rosa, Kevin and Hu, Derek Hao and Chang, Shih-Fu},
    title     = {Open-Vocabulary Object Detection Using Captions},
    booktitle = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021},
    pages     = {14388--14397},
    doi       = {10.1109/CVPR46437.2021.01416}
}

@inproceedings{zhaiSigmoidLossLanguage2023,
    author    = {Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
    title     = {Sigmoid Loss for Language Image Pre-Training},
    booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
    year      = {2023},
    pages     = {11941--11952},
    doi       = {10.1109/ICCV51070.2023.01100}
}

@article{zhangFlexibleNewTechnique2000,
  title = {A Flexible New Technique for Camera Calibration},
  author = {Zhang, Z.},
  date = {2000-11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {22},
  number = {11},
  pages = {1330--1334},
  issn = {1939-3539},
  doi = {10.1109/34.888718},
  url = {https://ieeexplore.ieee.org/document/888718/citations},
  urldate = {2026-01-18},
  abstract = {We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.},
  keywords = {Calibration,Cameras,Closed-form solution,Computer simulation,Computer vision,Layout,Lenses,Maximum likelihood estimation,Nonlinear distortion,Testing},
  file = {/home/kevin/snap/zotero-snap/common/Zotero/storage/QNNITHB8/citations.html}
}

@article{zhanSemanticExplorationDense2025,
    author  = {Zhan, Xiaoyang and Zhou, Shixin and Yang, Qianqian and Zhao, Yixuan and Liu, Hao and Ramineni, Srinivas Chowdary and Shimada, Kenji},
    title   = {Semantic Exploration and Dense Mapping of Complex Environments Using Ground Robot With Panoramic LiDAR-Camera Fusion},
    journal = {IEEE Robotics and Automation Letters},
    year    = {2025},
    volume  = {10},
    number  = {11},
    pages   = {11196--11203},
    doi     = {10.1109/LRA.2025.3609216}
}

@inproceedings{zhouBuildingAICPSNVIDIA2024,
  title            = {Towards Building {AI-CPS} with {NVIDIA Isaac Sim}: An Industrial Benchmark and Case Study for Robotics Manipulation},
  shorttitle       = {AI-CPS with Isaac Sim},
  author           = {Zhou, Zhehua and Song, Jiayang and Xie, Xuan and Shu, Zhan and Ma, Lei and Liu, Dikai and Yin, Jianxiong and See, Simon},
  booktitle        = {Proceedings of the IEEE--ACM International Conference on Software Engineering},
  booktitleaddon   = {Software Engineering in Practice},
  eventtitle       = {ICSE-SEIP},
  date             = {2024},
  pages            = {263--274},
  doi              = {10.1145/3639477.3639740}
}

@misc{zhouESCExplorationSoft2023,
    author        = {Zhou, Kaiwen and Zheng, Kaizhi and Pryor, Connor and Shen, Yilin and Jin, Hongxia and Getoor, Lise and Wang, Xin Eric},
    title         = {{ESC}: {Exploration} with {Soft Commonsense Constraints} for {Zero-shot Object Navigation}},
    year          = {2023},
    eprint        = {2301.13166},
    archivePrefix = {arXiv},
    primaryClass  = {cs.AI},
    doi           = {10.48550/arXiv.2301.13166},
    url           = {https://arxiv.org/abs/2301.13166}
}

@inproceedings{zouSegmentEverythingEverywhere2023,
  title      = {Segment Everything Everywhere All at Once},
  shorttitle = {SEEM},
  author     = {Zou, Xueyan and Yang, Jianwei and Zhang, Hao and Li, Feng and Li, Linjie and Wang, Jianfeng and Wang, Lijuan and Gao, Jianfeng and Lee, Yong Jae},
  booktitle  = {Proceedings of the International Conference on Neural Information Processing Systems},
  eventtitle = {NeurIPS},
  date       = {2023},
  publisher  = {Curran Associates},
  location   = {Red Hook, NY, USA}
}
