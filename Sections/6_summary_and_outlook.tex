% chktex-file 44

\chapter{Summary and Outlook}
\label{ch:conclusion}

Open-vocabulary semantic exploration in unstructured environments represents a fundamental challenge at the intersection of robotics, computer vision, and natural language understanding. Autonomous agents must not only navigate efficiently through unknown spaces, but also reason about semantically meaningful targets specified at runtime, under conditions of partial observability, perceptual ambiguity, and limited computational resources.

Prior work in semantic exploration has primarily followed two directions. Reinforcement learning-based approaches achieve strong performance through extensive training in simulation~\cite{majumdarZSONZeroShotObjectGoal2023,ramakrishnanPONIPotentialFunctions2022,ramrakhyaPIRLNavPretrainingImitation2023}, but often suffer from limited generalization and high training costs. In contrast, recent zero-shot methods leverage \acp{VLM} to guide exploration toward semantically relevant regions without task-specific training~\cite{yokoyamaVLFMVisionLanguageFrontier2023,gadreCoWsPastureBaselines2022}. To further improve efficiency, several frameworks incorporate persistent semantic maps to accumulate knowledge over time and reduce redundant observations~\cite{buschOneMapFind2025,huangVisualLanguageMaps2023}. However, existing methods either rely exclusively on semantic maps for decision-making or omit persistent mapping entirely, which can lead to brittle behavior, inefficient exploration, or limited robustness to perceptual noise. Moreover, many approaches do not explicitly fuse multi-source semantic evidence, leaving object detection performance vulnerable to false negatives and inconsistent observations.

This thesis introduced \textbf{SAGE}, a hybrid open-vocabulary semantic exploration framework that combines frontier-based exploration with persistent semantic memory and vision-language reasoning. By integrating reactive semantic frontier scoring with accumulated semantic maps, \textbf{SAGE} balances exploration of unseen space and exploitation of previously acquired knowledge. A multi-source fusion strategy further enhances robustness by combining detection confidence, vision-language similarity, and temporal memory evidence, allowing the system to reinforce consistent semantic hypotheses across viewpoints and time.

Extensive experiments conducted in the IsaacSim environment using the HM3Dv2 dataset~\cite{ramakrishnanHabitatMatterport3DDataset2021} demonstrate that \textbf{SAGE} achieves competitive and often superior performance compared to existing semantic exploration frameworks, particularly in terms of success rate and navigation efficiency. The results indicate that even in the presence of noisy semantic maps, a carefully balanced interaction between frontier-based exploration and map-based exploitation can substantially improve overall system performance. Penalizing frontiers near obstacles through costmap inflation further reduces failure cases in cluttered environments, resulting in smoother and more reliable exploration behavior. In addition, the proposed multi-source semantic fusion significantly reduces false negatives in object detection, leading to improved downstream decision-making despite a moderate increase in false positives.

Beyond performance, this work emphasizes system efficiency and practical deployability. Compared to prior vision-language frontier methods such as VLFM~\cite{yokoyamaVLFMVisionLanguageFrontier2023}, which require multiple \acp{VLM} and exceed 16\,GB of GPU memory in typical configurations, \textbf{SAGE} employs a streamlined perception pipeline with substantially lower memory requirements. The exploration components require approximately 3.5\,GB of GPU memory, and when combined with a medium-sized semantic map of roughly 200{,}000 voxels, the total memory footprint remains below 10\,GB. This makes the framework suitable for deployment on consumer-grade GPUs or for distributed setups in which the semantic memory is offloaded to a separate compute unit.

Despite these encouraging results, several avenues for future work remain. First, the semantic mapping backbone could be replaced or augmented with more advanced open-vocabulary mapping frameworks that provide improved fusion quality and uncertainty handling, such as OTAS~\cite{schwaigerOTASOpenvocabularyToken2025} or DualMap~\cite{jiangDualMapOnlineOpenVocabulary2025}. Second, the exploration-exploitation balance in \textbf{SAGE} is currently governed by a fixed hyperparameter. Adaptive strategies that adjust this balance online based on environmental complexity, task progress, or perceptual confidence could further improve robustness and efficiency. Finally, higher-level task reasoning could be incorporated by leveraging \acp{LLM} through existing ROS~2 action interfaces. Such models could generate sub-goals, adjust decision thresholds, or modulate exploration behavior dynamically, enabling more complex and long-horizon tasks to be executed autonomously.

In summary, \textbf{SAGE} demonstrates the potential of hybrid semantic exploration strategies that combine reactive perception, persistent memory, and multi-source semantic fusion. By bridging the gap between frontier-based exploration and semantic mapping, the proposed framework advances the state of open-vocabulary robotic navigation toward more adaptive, robust, and resource-efficient autonomous systems capable of operating in diverse real-world environments.
