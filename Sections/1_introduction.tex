% chktex-file 44

\chapter{Introduction}

Service and industrial robots are increasingly deployed in environments that require autonomous understanding and interaction beyond geometric navigation. Many real-world applications demand that robots not only map and explore their surroundings but also identify, locate, and reason about semantically meaningful objects within them. These tasks extend beyond simple localization and mapping, requiring semantic awareness and the ability to interpret open-ended instructions provided through natural language or multimodal input.

\textbf{Domain and Relevance.}
The demand for robust and adaptive semantic exploration is evident across several domains:

\begin{itemize}
    \item \textbf{Service Robotics:} A domestic vacuum robot may be instructed to find and approach a specific household object, such as a fridge in the kitchen, using a semantic input prompt rather than fixed coordinates or predefined waypoints\cite{gargSemanticsRoboticMapping2020}.
    \item \textbf{Search and Rescue (SAR):} In emergency scenarios, autonomous ground or aerial robots are deployed to search for persons with incomplete or uncertain information, such as a hint that a missing individual may be located in a bathroom or behind a closed door\cite{ruanTaxonomySemanticInformation2022}.
    \item \textbf{Inspection:} Industrial or infrastructure inspection robots must autonomously explore and analyze previously uncharted or unteleoperable areas, guided by semantic instructions (e.g., “inspect the corroded pipe near the valve”)\cite{almadhounSurveyInspectingStructures2016}.
    \item \textbf{Warehouse Automation:} Large-scale warehouses often contain thousands of storage units or pallets that may not be consistently labeled or easily visible. Semantic perception enables robots to efficiently locate and retrieve items that match high-level descriptions (e.g., “find the blue container behind the conveyor belt”)\cite{almadhounSurveyInspectingStructures2016}.
\end{itemize}

In all of these use cases, the integration of semantic understanding with autonomous navigation is critical. Robots must be capable of interpreting abstract human instructions, reasoning about spatial and semantic context, and performing efficient searches in complex, dynamic environments. This motivates the development of a unified framework that bridges geometric exploration with semantic scene understanding.

\section{Problem Statement}

\textbf{Problem:} Classic geometric exploration methods often lead to inefficient search behavior, as they are primarily designed for mapping unexplored environments rather than for goal-directed semantic search tasks.

\textbf{Solution:} Incorporating semantic reasoning into exploration by using RGB camera input to associate geometric frontiers with language-based meaning and task relevance.

\textbf{Current solutions:}

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{
    |>{\raggedright\arraybackslash}X
    |>{\centering\arraybackslash}m{2.2cm}
    |>{\centering\arraybackslash}m{2cm}
    |>{\raggedright\arraybackslash}X|}
    \hline
    \textbf{Approach} & \textbf{Training Required} & \textbf{Real-Time} & \textbf{Semantic Reasoning Model} \\ \hline
    \textbf{VLFM} & \xmark~(zero-shot) & \cmark& BLIP-2 + GroundingDINO + SAM \\ \hline
\textbf{SemUtil} & \xmark~(training-free) & \cmark& Mask R-CNN + CLIP + BERT \\ \hline
\textbf{ESC} & \xmark~(zero-shot) & \cmark& GLIP + DeBERTa / ChatGPT reasoning \\ \hline
\textbf{LGX} & \xmark~(zero-shot) & \cmark& GPT-3 + GLIP + BLIP \\ \hline
\textbf{CoW} & \xmark~(zero-shot) & \cmark& CLIP similarity scoring \\ \hline
\textbf{ZSON} & \cmark~(RL pretraining) & \xmark& CLIP-based RL policy \\ \hline
\textbf{PONI} & \cmark~(supervised) & \xmark& Learned potential-field network \\ \hline
\textbf{PIRLNav} & \cmark~(BC + RL) & \xmark& DINO-based CNN-RNN policy \\ \hline
\end{tabularx}
\caption{Overview of Semantic Exploration Approaches without Persistent Memory}
\end{table}

None of the above methods incorporate a persistent semantic memory for efficient multi-object navigation and are often computationally demanding.

\textbf{Problem:} 
\begin{itemize}
    \item Lack of persistent memory in semantic exploration frameworks limits long-term efficiency in multi-object search tasks.
    \item Existing methods often require extensive offline training, reducing adaptability to new environments.
    \item Deep Reinforcement Learning (DRL) approaches are computationally expensive and lack persistent memory for effective multi-object goal search.
\end{itemize}

\textbf{Current solutions:}

\begin{table}[H]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.0}
\setlength{\tabcolsep}{3pt}
\begin{tabularx}{\textwidth}{
|>{\raggedright\arraybackslash}X
|>{\centering\arraybackslash}X
|>{\centering\arraybackslash}X
|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Approach} & \textbf{Training Required} & \textbf{Real-Time} & \textbf{Semantic Reasoning Model} \\ \hline
\textbf{VLFM} & \xmark~(zero-shot) & \cmark & BLIP-2 + GroundingDINO + SAM \\ \hline
\textbf{SemUtil} & \xmark~(training-free) & \cmark & Mask R-CNN + CLIP + BERT \\ \hline
\textbf{ESC} & \xmark~(zero-shot) & \cmark & GLIP + DeBERTa / ChatGPT reasoning \\ \hline
\textbf{LGX} & \xmark~(zero-shot) & \cmark & GPT-3 + GLIP + BLIP \\ \hline
\textbf{CoW} & \xmark~(zero-shot) & \cmark & CLIP similarity scoring \\ \hline
\textbf{ZSON} & \cmark~(RL pretraining) & \xmark & CLIP-based RL policy \\ \hline
\textbf{PONI} & \cmark~(supervised) & \xmark & Learned potential-field network \\ \hline
\textbf{PIRLNav} & \cmark~(BC + RL) & \xmark & DINO-based CNN-RNN policy \\ \hline
\end{tabularx}
\caption{Overview of Semantic Zero-Shot and Trained Exploration Approaches}
\end{table}


!!!!!!!!!!! Add chaplot2020semexp !!!!!!!!!!!!!!!!!!!


Despite notable progress, these methods often suffer from heavy GPU requirements, offline training procedures, or noisy semantic maps that reduce navigation reliability. Some further depend heavily on object detectors, which can introduce false positives in open-vocabulary settings.

\bigskip
\textbf{Core Gaps in Existing Work:}

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{
        |>{\raggedright\arraybackslash}m{4cm}
        |>{\raggedright\arraybackslash}m{4cm}
        |>{\raggedright\arraybackslash}X|}
        \hline
        \textbf{Limitation} & \textbf{Example Works} & \textbf{Implication} \\ \hline
        No persistent memory & VLFM, CoW, LGX, ESC & No long-term fusion or recall; repeated exploration of known areas. \\ \hline
        Offline training required & ZSON, PONI, PIRLNav, SemExp & Heavy RL/supervised training; poor adaptability to new scenes. \\ \hline
        No balance between exploration and memory & OneMap, RayFronts, VLMaps & Either passive mapping or short-term exploration; inefficient search. \\ \hline
        No zero-shot exploration & VLFM, CoW, LGX & Detect novel objects but fail to explore unseen regions strategically. \\ \hline
        Premapping needed & ConceptGraphs, VLMaps, GeFF & Depend on pre-recorded data; not suited for online autonomy. \\ \hline
        Limited robustness & PONI, SemExp, PIRLNav & Closed-set categories; fragile under real-world variation. \\ \hline
        Low real-world applicability & ConceptGraphs, VLMaps & High GPU cost or simulation-only; not deployable on mobile robots. \\ \hline
    \end{tabularx}
\caption{Identified Gaps in Existing Semantic Exploration Frameworks}
\end{table}

\bigskip
\textbf{Derived Requirements from the State of the Art:}
\begin{itemize}
    \item Zero-shot frontier exploration framework.
    \item Persistent 3D semantic mapping with confidence-based fusion.
    \item Use of pretrained models only (no additional training required).
    \item Hybrid fusion strategy to balance exploration and memory.
    \item Multi-source detection fusion for robust object identification.
    \item GPU-efficient design for real-time deployment on mobile robots.
    \item Modular architecture for easy adaptation and extension.
    \item Independence from fixed, pre-trained object category sets.
\end{itemize}

\section{Scientific Contribution}

This work contributes to the state of the art by introducing a hybrid semantic exploration framework that integrates zero-shot semantic frontier scoring with persistent 3D scene representation, enabling autonomous search guided by open-vocabulary text queries. The system combines real-time semantic reasoning during exploration with a long-term spatial memory, allowing the robot to dynamically balance between discovering new information and exploiting previously acquired knowledge.

Unlike previous approaches that focus exclusively on either geometric frontiers or static semantic maps, the proposed framework continuously fuses information from multiple semantic sources to maintain a unified, confidence-based world model. Adaptive weighting enables the robot to adjust its behavior between exploration and exploitation according to the reliability of recent observations and the stability of stored semantic memory.

The framework further investigates how the quality and granularity of the underlying semantic information influence task success, navigation efficiency, and robustness. By systematically varying the trust between exploration and memory components, this work provides new insights into how semantic reasoning and persistent mapping can be effectively combined for open-vocabulary, multi-object search in dynamic environments.

To evaluate the contribution of the proposed system, the following research questions are formulated:

\begin{enumerate}
    \item \textbf{How does integrating zero-shot semantic exploration and persistent 3D semantic mapping affect multi-object search performance and navigation efficiency compared to existing methods?} \\
    \textit{Metrics:} Performance is quantified in terms of task success and path efficiency, measured through Success Rate (SR), Success per Path Length (SPL), and Multi-Object Success Rate (MSR) relative to representative state-of-the-art systems such as OneMap, VLFM, and Pigeon.
    
    \item \textbf{How does the interaction between live exploration and accumulated semantic memory influence overall system performance?} \\
    \textit{Metrics:} The weighting factor between exploration and memory is varied during graph node fusion to assess impacts on SR and SPL, identifying optimal trade-offs between reactivity and exploitation.
    
    \item \textbf{How does the granularity of semantic map retrieval affect map quality, and can dynamic weighting between exploration and memory compensate for potential noise?} \\
    \textit{Metrics:} The semantic granularity in the 3D semantic mapper is varied while adjusting exploration weight to evaluate effects on SR and SPL\@.
    
    \item \textbf{How does multi-source fusion of detection confidence, semantic similarity, and memory confidence impact detection robustness and false-positive suppression during exploration?} \\
    \textit{Metrics:} Precision, Recall, F1-Score, Confusion Matrix, and SR under different fusion weight configurations across COCO, open-vocabulary, and zero-shot classes.
    
    \item \textbf{What is the computational footprint and real-world robustness of the hybrid framework?} \\
    \textit{Metrics:} Frames per second (FPS), GPU/CPU usage, inference latency, and detection stability under sensor noise during physical deployment on a mobile robot.
\end{enumerate}

These research questions guide the design of the experimental evaluation, where each question is systematically addressed through targeted ablation studies, comparative benchmarks, and real-world validation presented in Chapter~\ref{ch:results}.

\section{Thesis Structure}
