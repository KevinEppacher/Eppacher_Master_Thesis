% chktex-file 44

\chapter{Discussion and Results}
\label{ch:results}
Aim of this chapter is to anser the research questions posed in Chapter~\ref{ch:introduction} through a series of experiments designed to evaluate the performance of the proposed multi-object search framework. The first experiment establishes baseline performance against state-of-the-art methods, while subsequent experiments systematically analyze the impact of key design choices on navigation efficiency, mapping robustness, and detection reliability. Each experiment is structured to isolate specific variables, allowing for a clear assessment of their contributions to overall system performance.

\section{Experiment 1: Benchmarking on Matterport Scenes}
\label{sec:experiments:results:1}
Evaluates baseline performance in multi-object search compared to state-of-the-art frameworks (OneMap, VLFM, Pigeon) using SR, SPL, and MSR.

\section{Experiment 2: Impact of Exploration-Memory Weighting}
\label{sec:experiments:results:2}

This experiment directly addresses \textbf{RQ2} by analyzing how the balance between live exploration and accumulated semantic memory influences navigation performance and failure characteristics. The results in Figures~\ref{fig:results:rq2:sr} and~\ref{fig:results:rq2:spl} indicate that the optimal trade-off between reactivity to new observations and exploitation of accumulated knowledge occurs at an intermediate exploitation weight, between 0.2 and 0.4.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/sr.png}
        \subcaption{\ac{SR}}
        \label{fig:results:rq2:sr}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/spl.png}
        \subcaption{\ac{SPL}}
        \label{fig:results:rq2:spl}
    \end{minipage}

    \caption{Navigation performance as a function of the exploration-memory weighting in Experiment~2. 
    SR captures task success, while SPL reflects navigation efficiency conditioned on success.}
    \label{fig:results:rq2:performance}
\end{figure}

To contextualize the observed performance trends, the failure mode distributions
summarized in Figure~\ref{fig:results:rq2:failure_mode_breakdown_across_scenes}
and the comparative breakdowns in
Figure~\ref{fig:results:rq2:failure_mode_comparison}
illustrate how different exploration-memory weighting strategies affect the types
of failures encountered.

Across all configurations, misdetection is the dominant failure mode, accounting
for 11.6\% of all evaluated episodes. This is followed by failures caused by not
observing the target object (4.9\%) and by ignoring the target despite successful
observation (4.6\%).

The prevalence of misdetections is primarily driven by the failure mode
\texttt{Stopped at wrong object}, indicating premature commitment to visually or
semantically similar distractors. As discussed in
Section~\ref{sec:experiments:results:4}, this behavior is a direct consequence of
over-reliance on semantic memory cues that may include false positives. In contrast,
failures categorized as \texttt{Did not see target} are mainly attributable to
incomplete environment coverage or temporary occlusions during exploration, whereas
\texttt{Ignored target} failures arise from conservative thresholding or semantic
ambiguity that suppresses confident target selection despite visual availability.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/failure_mode_breakdown.png}
    \caption{Aggregate failure mode distribution across all exploration-memory weight configurations for Experiment~2.}
    \label{fig:results:rq2:failure_mode_breakdown_across_scenes}
\end{figure}

Figures~\ref{fig:results:rq2:exp_60_failure_mode} and~\ref{fig:results:rq2:exp_40_failure_mode} illustrate the failure mode distributions for exploitation weights of 0.6 and 0.4, respectively. At an exploitation weight of 0.6, the system relies more on semantic memory, which can introduce misleading memory cues during early exploration stages. OpenFusion~\cite{yamazakiOpenFusionRealtimeOpenVocabulary2023} retrieves the top-$k$ most relevant semantic clusters from its embedding dictionary to enable zero-shot generalization. However, if the semantic memory contains false positives, these cues may guide the robot toward visually or semantically similar but incorrect objects before sufficient direct observations are available.

In contrast, at an exploitation weight of 0.4, the system remains more responsive to newly acquired observations. This increased reactivity enables the correction of spurious semantic hypotheses stored in memory, while still allowing accumulated knowledge to guide exploration toward promising regions when semantic frontier nodes exhibit low confidence. As a result, the balance between exploration and memory exploitation reduces premature commitment to incorrect targets.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/exp_60_failure_mode_breakdown.png}
        \subcaption{Exploitation weight $\lambda_{\mathrm{exploit}} = 0.6$}
        \label{fig:results:rq2:exp_60_failure_mode}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/exp_40_failure_mode_breakdown.png}
        \subcaption{Exploitation weight $\lambda_{\mathrm{exploit}} = 0.4$}
        \label{fig:results:rq2:exp_40_failure_mode}
    \end{minipage}

    \caption{Failure mode breakdowns for two exploration-memory weighting configurations in Experiment~2. 
    A higher exploitation weight increases susceptibility to misdetections due to premature reliance on semantic memory, 
    while a more balanced weighting reduces false positives by incorporating corrective exploratory evidence.}
    \label{fig:results:rq2:failure_mode_comparison}
\end{figure}

At the extremes, pure exploration (0.0 exploitation weight) and pure exploitation (1.0 exploitation weight) exhibit similar \ac{SPL} scores, indicating that both strategies lead to inefficient navigation behavior. While pure exploration allows the robot to adapt to newly observed evidence, it fails to leverage previously acquired semantic knowledge. Conversely, pure exploitation overly commits to stored memory cues, which may include false positives that cannot be corrected without sufficient exploratory evidence. The slightly higher \ac{SR} observed for pure exploration compared to pure exploitation further suggests that adaptability to new observations is preferable to rigid reliance on semantic memory.

Overall, these results demonstrate that the interaction between exploration and memory is inherently non-linear. Semantic memory is essential for efficient long-horizon search. However, excessive reliance on memory leads to premature commitment to noisy or incomplete hypotheses that degrade performance. Furthermore, if no cues are in the semantic memory, the robot effectively operates in a blind exploration mode, by exploring randomly, resulting in inefficient navigation.

An exploitation weight between 0.2 and 0.4 provides the most robust balance, yielding improved navigation efficiency and task success. Consequently, an exploitation weight of 0.4 is selected for all subsequent experiments, as it achieves the best overall performance in this study.

\section{Experiment 3: Sensitivity to Semantic Map Granularity}
\label{sec:experiments:results:3}

This experiment proves, that even if the map granularity is varied significantly by adjusting the top-k retrieval parameter in OpenFusion~\cite{yamazakiOpenFusionRealtimeOpenVocabulary2023}, the navigation performance remains relatively stable. Figure~\ref{fig:results:rq3:map_granularity_example} illustrates how different top-k values affect the density and noise characteristics of the resulting semantic map. As expected, lower top-k values (e.g., top-1) yield sparser but cleaner semantic representations, while higher top-k values (e.g., top-60) produce denser maps with increased noise levels, but more cues for semantically similar objects. However, for OpenFusion~\cite{yamazakiOpenFusionRealtimeOpenVocabulary2023}, higher top-k values also introduce more false positives, which can been seen for example for the prompt \texttt{"couch"}, which marks a stove and a table as a couch (see Figure~\ref{fig:results:rq3:map_granularity_example}).

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/map_granularity_example.png}
    \caption{TODO: Replace with relevant figure for Experiment 3}
    \label{fig:results:rq3:map_granularity_example}
\end{figure}

For all 60 multi-object episodes, with 324 object-level queries in total, the trade-off balance between exploration and memory exploitation to to pure exploitation, shows that a the 60\% exploration--40\% memory configuration consistently outperforms a pure exploitation strategy (100\% memory) across all top-k values, as shown in Figures~\ref{fig:results:rq3:sr} and~\ref{fig:results:rq3:spl}, in both \ac{SR} and \ac{SPL} metrics. This finding reinforces the conclusions from Experiment~2, highlighting the benefits of maintaining a balance between responsiveness to new observations and leveraging accumulated semantic knowledge.

As OpenFusion~\cite{yamazakiOpenFusionRealtimeOpenVocabulary2023} memory backbone, the best performance is achieved at a top-k value of 15, which provides a good compromise between map density and noise. However, the performance differences across top-k values are relatively minor, indicating that the proposed framework is robust to variations in semantic map granularity. Moreover, the \ac{IQR} for pure exploitation (100\% memory) is significantly larger than for the balanced configuration (60\% exploration), suggesting that relying solely on semantic memory increases susceptibility to noise introduced by higher top-k values.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/sr.png}
        \subcaption{\ac{SR} as a function of semantic map granularity}
        \label{fig:results:rq3:sr}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/spl.png}
        \subcaption{\ac{SPL} as a function of semantic map granularity}
        \label{fig:results:rq3:spl}
    \end{minipage}

    \caption{Impact of semantic map retrieval granularity (top-$k$) on navigation performance in Experiment~3.
    Results are shown for a memory-dominant configuration (100\% exploitation) and a balanced configuration
    (60\% exploration).}
    \label{fig:results:rq3:performance}
\end{figure}

To further elucidate the effects of semantic map granularity on failure modes, Figures~\ref{fig:results:rq3:exp_60_failure_mode} and~\ref{fig:results:rq3:exp_0_failure_mode} present failure mode breakdowns for the balanced (60\% exploration) and pure exploitation (100\% exploitation) configurations, respectively. On average has a total failures of 18.0\% for the balanced configuration and 34.2\% for the pure exploitation configuration. Interstingly, the biggest failure rate of the 60\% exploration configuration is \texttt{"Stopped ar wrong object"} with 8.0\%, which is a similar failure rate as for the pure exploitation configuration with 8.1\%. This further proves, that the detection pipeline is nicely decoupled from exploration and memory strategies and remains consistent across different configurations. However, the pure exploitation configuration shows significantly higher failure rates for \texttt{"Did not see goal"} with 12.8\% and \texttt{"Ignored target"} with 6.0\%, compared to only 2.0\% and 7.3\% for the balanced configuration, respectively. This indicates, that further guiding the robot towards semantically promising regions through exploration helps to mitigate failures related to incomplete environment coverage and conservative target selection. Interestingly, the failure mode \texttt{"Navigation failure"} is significantly higher for the pure exploitation configuration with 7.4\% compared to only 0.7\% for the balanced configuration, which indicates the effect of punishing graph nodes near to obstacles during exploration, which helps to avoid navigation failures through better path planning. With respect to solely exploration, \ac{VLFM}~\cite{yokoyamaVLFMVisionLanguageFrontier2023} only scores based on the cosine similarity from the \ac{VLM} , whereas the proposed framework also incorporates scores Frontiers, based on the costmap and rewards closer frontiers to the robot, which further helps to avoid navigation failures.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/exp_60_failure_mode_breakdown.png}
        \subcaption{Balanced configuration (60\% exploration)}
        \label{fig:results:rq3:exp_60_failure_mode}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/exp_0_failure_mode_breakdown.png}
        \subcaption{Pure exploitation (100\% exploitation)}
        \label{fig:results:rq3:exp_0_failure_mode}
    \end{minipage}

    \caption{Failure mode breakdowns for Experiment~3 under different exploration--memory weighting configurations.
    A higher reliance on semantic memory increases susceptibility to observation-related failures,
    while a balanced exploration-memory strategy mitigates premature commitment and improves robustness.}
    \label{fig:results:rq3:failure_mode_comparison}
\end{figure}


\section{Experiment 4: Effect of Multi-Source Semantic Fusion}
\label{sec:experiments:results:4}

Examines how combining detection confidence, semantic similarity, and memory reliability improves detection robustness and reduces false positives.

\begin{table}[H]
    \centering
    \footnotesize
    \renewcommand{\arraystretch}{1.25}
    \begin{tabular}{l c c c c c c c c c}
        \toprule
        Fusion Variant & $\tau$ &
        $P\,(\uparrow)$ &
        $R\,(\uparrow)$ &
        $F1\,(\uparrow)$ &
        $FPR\,(\downarrow)$ &
        TP & FP & FN & TN \\
        \midrule
        % ===== tau = 0.5 =====
        Single source detection
            & 0.5 & \textbf{0.910} & 0.909 & 0.910 & \textbf{0.364} & 528 & 52 & 53 & 91 \\
        Detection + VLM score
            & 0.5 & 0.903 & \textbf{0.928} & \textbf{0.915} & 0.406 & 539 & 58 & 42 & 85 \\
        Detection + Memory
            & 0.5 & 0.909 & 0.914 & 0.912 & 0.371 & 531 & 53 & 50 & 90 \\
        Multi-source Fusion
            & 0.5 & 0.906 & 0.917 & 0.912 & 0.385 & 533 & 55 & 48 & 88 \\
        \midrule
        % ===== tau = 0.6 =====
        Single source detection
            & 0.6 & \textbf{0.914} & 0.892 & 0.902 & \textbf{0.343} & 518 & 49 & 63 & 94 \\
        Detection + VLM score
            & 0.6 & 0.910 & \textbf{0.910} & \textbf{0.910} & 0.364 & 529 & 52 & 52 & 91 \\
        Detection + Memory
            & 0.6 & 0.910 & 0.905 & 0.908 & 0.364 & 526 & 52 & 55 & 91 \\
        Multi-source Fusion
            & 0.6 & 0.910 & \textbf{0.910} & \textbf{0.910} & 0.364 & 529 & 52 & 52 & 91 \\
        \midrule
        % ===== tau = 0.8 =====
        Single source detection
            & 0.8 & \textbf{0.941} & 0.632 & 0.756 & \textbf{0.161} & 367 & 23 & 214 & 120 \\
        Detection + VLM score
            & 0.8 & 0.912 & 0.876 & 0.894 & 0.343 & 509 & 49 & 72 & 94 \\
        Detection + Memory
            & 0.8 & 0.913 & 0.799 & 0.852 & 0.308 & 464 & 44 & 117 & 99 \\
        Multi-source Fusion
            & 0.8 & 0.913 & \textbf{0.888} & \textbf{0.901} & 0.343 & 516 & 49 & 65 & 94 \\
        \bottomrule
    \end{tabular}
    \caption{Detection performance metrics across fusion strategies and thresholds.
    Arrows indicate whether higher ($\uparrow$) or lower ($\downarrow$) values are better.
    Best values per threshold $\tau$ are highlighted in bold. TODO: Check numbers. May need to be updated.}
\end{table}



\begin{figure}[h!]
\centering
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ4/cm_multi_source_fusion.png}
\caption{TODO: Replace with relevant figure for Experiment 4}
\label{fig:results:rq4:cm_multi_source_fusion}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ4/cm_detection_only.png}
\caption{TODO: Replace with relevant figure for Experiment 4}
\label{fig:results:rq4:cm_detection_only}
\end{minipage}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ4/pr_curve.png}
    \caption{TODO: Replace with relevant figure for Experiment 4}
    \label{fig:results:rq4:pr_curve}
\end{figure}

\section{Experiment 5: System Efficiency and Real-World Validation}
\label{sec:experiments:results:5}

Assesses runtime performance, resource utilization, and stability under real-world sensor noise during physical deployment.

\newpage