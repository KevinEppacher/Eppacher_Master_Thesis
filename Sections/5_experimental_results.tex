% chktex-file 44

\chapter{Discussion and Results}
\label{ch:results}
Aim of this chapter is to anser the research questions posed in Chapter~\ref{ch:introduction} through a series of experiments designed to evaluate the performance of the proposed multi-object search framework. The first experiment establishes baseline performance against state-of-the-art methods, while subsequent experiments systematically analyze the impact of key design choices on navigation efficiency, mapping robustness, and detection reliability. Each experiment is structured to isolate specific variables, allowing for a clear assessment of their contributions to overall system performance.

\section{Experiment 1: Benchmarking on Matterport Scenes}
\label{sec:experiments:results:1}
Evaluates baseline performance in multi-object search compared to state-of-the-art frameworks (OneMap, VLFM, Pigeon) using SR, SPL, and MSR.


\section{Experiment 2: Impact of Exploration-Memory Weighting}
\label{sec:experiments:results:2}

This experiment directly addresses \textbf{RQ2} by analyzing how the balance between live exploration and accumulated semantic memory influences navigation performance and failure characteristics. The results in Figures~\ref{fig:results:rq2:sr} and~\ref{fig:results:rq2:spl} indicate that the optimal trade-off between reactivity to new observations and exploitation of accumulated knowledge occurs at an intermediate exploitation weight, between 0.2 and 0.4.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/sr.png}
        \subcaption{\ac{SR}}
        \label{fig:results:rq2:sr}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/spl.png}
        \subcaption{\ac{SPL}}
        \label{fig:results:rq2:spl}
    \end{minipage}

    \caption{Navigation performance as a function of the exploration-memory weighting in Experiment~2. 
    SR captures task success, while SPL reflects navigation efficiency conditioned on success.}
    \label{fig:results:rq2:performance}
\end{figure}

\begin{table}[h!]
    \centering
    \footnotesize
    \renewcommand{\arraystretch}{1.1}
    \begin{tabular}{l c}
        \toprule
        \textbf{Statistic} & \textbf{Value} \\
        \midrule
        Total episodes evaluated & 12 \\
        Multi-object episodes & 12 \\
        Total object queries (prompts) & 345 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation scale for Experiment~2 (Exploration--Memory Weighting).}
    \label{tab:rq2:evaluation_scale}
\end{table}


To contextualize the observed performance trends, the failure mode distributions
summarized in Figure~\ref{fig:results:rq2:failure_mode_breakdown_across_scenes}
and the comparative breakdowns in
Figure~\ref{fig:results:rq2:failure_mode_comparison}
illustrate how different exploration–memory weighting strategies affect the types
of failures encountered.

Across all configurations, misdetection is the dominant failure mode, accounting
for 11.6\% of all evaluated episodes. This is followed by failures caused by not
observing the target object (4.9\%) and by ignoring the target despite successful
observation (4.6\%).

The prevalence of misdetections is primarily driven by the failure mode
\texttt{Stopped at wrong object}, indicating premature commitment to visually or
semantically similar distractors. As discussed in
Section~\ref{sec:experiments:results:4}, this behavior is a direct consequence of
the Noisy-OR fusion strategy, which is intentionally permissive when aggregating
weak but consistent detection evidence and is therefore susceptible to false
positives.

Failures categorized as \texttt{Did not see target} are mainly attribut
\section{Experiment 2: Impact of Exploration-Memory Weighting}
\label{sec:experiments:results:2}

This experiment directly addresses \textbf{RQ2} by analyzing how the balance between live exploration and accumulated semantic memory influences navigation performance and failure characteristics. The results in Figures~\ref{fig:results:rq2:sr} and~\ref{fig:results:rq2:spl} indicate that the optimal trade-off between reactivity to new observations and exploitation of accumulated knowledge occurs at an intermediate exploitation weight, between 0.2 and 0.4.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/sr.png}
        \subcaption{\ac{SR}}
        \label{fig:results:rq2:sr}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/spl.png}
        \subcaption{\ac{SPL}}
        \label{fig:results:rq2:spl}
    \end{minipage}

    \caption{Navigation performance as a function of the exploration-memory weighting in Experiment~2. 
    SR captures task success, while SPL reflects navigation efficiency conditioned on success.}
    \label{fig:results:rq2:performance}
\end{figure}

To contextualize the observed performance trends, the failure mode distributions
summarized in Figure~\ref{fig:results:rq2:failure_mode_breakdown_across_scenes}
and the comparative breakdowns in
Figure~\ref{fig:results:rq2:failure_mode_comparison}
illustrate how different exploration–memory weighting strategies affect the types
of failures encountered.

Across all configurations, misdetection is the dominant failure mode, accounting
for 11.6\% of all evaluated episodes. This is followed by failures caused by not
observing the target object (4.9\%) and by ignoring the target despite successful
observation (4.6\%).

The prevalence of misdetections is primarily driven by the failure mode
\texttt{Stopped at wrong object}, indicating premature commitment to visually or
semantically similar distractors. As discussed in
Section~\ref{sec:experiments:results:4}, this behavior is a direct consable to
incomplete environment coverage or temporary occlusions during exploration,
whereas \texttt{Ignored target} failures arise from conservative thresholding or
semantic ambiguity that suppresses confident target selection despite visual
availability.


\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/failure_mode_breakdown.png}
    \caption{Aggregate failure mode distribution across all exploration-memory weight configurations for Experiment~2.}
    \label{fig:results:rq2:failure_mode_breakdown_across_scenes}
\end{figure}

Figures~\ref{fig:results:rq2:exp_60_failure_mode} and~\ref{fig:results:rq2:exp_40_failure_mode} illustrate the failure mode distributions for exploitation weights of 0.6 and 0.4, respectively. At an exploitation weight of 0.6, the system relies more heavily on accumulated semantic memory, which can introduce misleading memory cues during early exploration stages. OpenFusion~\cite{yamazakiOpenFusionRealtimeOpenVocabulary2023} retrieves the top-$k$ most relevant semantic clusters from its embedding dictionary to enable zero-shot generalization; however, if the semantic memory contains false positives, these cues may guide the robot toward visually or semantically similar but incorrect objects before sufficient direct observations are available.

In contrast, at an exploitation weight of 0.4, the system remains more responsive to newly acquired observations. This increased reactivity enables the correction of spurious semantic hypotheses stored in memory, while still allowing accumulated knowledge to guide exploration toward promising regions when semantic frontier nodes exhibit low confidence. As a result, the balance between exploration and memory exploitation reduces premature commitment to incorrect targets.

\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/exp_60_failure_mode_breakdown.png}
        \subcaption{Exploitation weight $\lambda_{\mathrm{exploit}} = 0.6$}
        \label{fig:results:rq2:exp_60_failure_mode}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ2/exp_40_failure_mode_breakdown.png}
        \subcaption{Exploitation weight $\lambda_{\mathrm{exploit}} = 0.4$}
        \label{fig:results:rq2:exp_40_failure_mode}
    \end{minipage}

    \caption{Failure mode breakdowns for two exploration--memory weighting configurations in Experiment~2. 
    A higher exploitation weight increases susceptibility to misdetections due to premature reliance on semantic memory, 
    while a more balanced weighting reduces false positives by incorporating corrective exploratory evidence.}
    \label{fig:results:rq2:failure_mode_comparison}
\end{figure}

At the extremes, pure exploration (0.0 exploitation weight) and pure exploitation (1.0 exploitation weight) exhibit similar \ac{SPL} scores, indicating that both strategies lead to inefficient navigation behavior. While pure exploration allows the robot to adapt to newly observed evidence, it fails to leverage previously acquired semantic knowledge. Conversely, pure exploitation overly commits to stored memory cues, which may include false positives that cannot be corrected without sufficient exploratory evidence. The slightly higher \ac{SR} observed for pure exploration compared to pure exploitation further suggests that adaptability to new observations is preferable to rigid reliance on semantic memory.

Overall, these results demonstrate that the interaction between exploration and memory is inherently non-linear. Semantic memory is essential for efficient long-horizon search; however, excessive reliance on memory leads to premature commitment to noisy or incomplete hypotheses that degrade performance. An exploitation weight between 0.2 and 0.4 provides the most robust balance, yielding improved navigation efficiency and task success. Consequently, an exploitation weight of 0.4 is selected for all subsequent experiments, as it achieves the best overall performance in this study.

\section{Experiment 3: Sensitivity to Semantic Map Granularity}
\label{sec:experiments:results:3}

Investigates how varying the semantic retrieval depth affects mapping robustness and overall navigation stability.

\begin{figure}[h!]
\centering
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/sr.png}
\caption{TODO: Replace with relevant figure for Experiment 3}
\label{fig:results:rq3:sr}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/spl.png}
\caption{TODO: Replace with relevant figure for Experiment 3}
\label{fig:results:rq3:spl}
\end{minipage}
\end{figure}

\begin{figure}[h!]
\centering
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/exp_60_failure_mode_breakdown.png}
\caption{TODO: Replace with relevant figure for Experiment 3}
\label{fig:results:rq3:sr}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ3/exp_0_failure_mode_breakdown.png}
\caption{TODO: Replace with relevant figure for Experiment 3}
\label{fig:results:rq3:spl}
\end{minipage}
\end{figure}

\section{Experiment 4: Effect of Multi-Source Semantic Fusion}
\label{sec:experiments:results:4}

Examines how combining detection confidence, semantic similarity, and memory reliability improves detection robustness and reduces false positives.

\begin{table}[H]
    \centering
    \footnotesize
    \renewcommand{\arraystretch}{1.25}
    \begin{tabular}{l c c c c c c c c c}
        \toprule
        Fusion Variant & $\tau$ &
        $P\,(\uparrow)$ &
        $R\,(\uparrow)$ &
        $F1\,(\uparrow)$ &
        $FPR\,(\downarrow)$ &
        TP & FP & FN & TN \\
        \midrule
        % ===== tau = 0.5 =====
        Single source detection
            & 0.5 & \textbf{0.910} & 0.909 & 0.910 & \textbf{0.364} & 528 & 52 & 53 & 91 \\
        Detection + VLM score
            & 0.5 & 0.903 & \textbf{0.928} & \textbf{0.915} & 0.406 & 539 & 58 & 42 & 85 \\
        Detection + Memory
            & 0.5 & 0.909 & 0.914 & 0.912 & 0.371 & 531 & 53 & 50 & 90 \\
        Multi-source Fusion
            & 0.5 & 0.906 & 0.917 & 0.912 & 0.385 & 533 & 55 & 48 & 88 \\
        \midrule
        % ===== tau = 0.6 =====
        Single source detection
            & 0.6 & \textbf{0.914} & 0.892 & 0.902 & \textbf{0.343} & 518 & 49 & 63 & 94 \\
        Detection + VLM score
            & 0.6 & 0.910 & \textbf{0.910} & \textbf{0.910} & 0.364 & 529 & 52 & 52 & 91 \\
        Detection + Memory
            & 0.6 & 0.910 & 0.905 & 0.908 & 0.364 & 526 & 52 & 55 & 91 \\
        Multi-source Fusion
            & 0.6 & 0.910 & \textbf{0.910} & \textbf{0.910} & 0.364 & 529 & 52 & 52 & 91 \\
        \midrule
        % ===== tau = 0.8 =====
        Single source detection
            & 0.8 & \textbf{0.941} & 0.632 & 0.756 & \textbf{0.161} & 367 & 23 & 214 & 120 \\
        Detection + VLM score
            & 0.8 & 0.912 & 0.876 & 0.894 & 0.343 & 509 & 49 & 72 & 94 \\
        Detection + Memory
            & 0.8 & 0.913 & 0.799 & 0.852 & 0.308 & 464 & 44 & 117 & 99 \\
        Multi-source Fusion
            & 0.8 & 0.913 & \textbf{0.888} & \textbf{0.901} & 0.343 & 516 & 49 & 65 & 94 \\
        \bottomrule
    \end{tabular}
    \caption{Detection performance metrics across fusion strategies and thresholds.
    Arrows indicate whether higher ($\uparrow$) or lower ($\downarrow$) values are better.
    Best values per threshold $\tau$ are highlighted in bold. TODO: Check numbers. May need to be updated.}
\end{table}



\begin{figure}[h!]
\centering
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ4/cm_multi_source_fusion.png}
\caption{TODO: Replace with relevant figure for Experiment 4}
\label{fig:results:rq4:cm_multi_source_fusion}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{Images/05_experimental_results/RQ4/cm_detection_only.png}
\caption{TODO: Replace with relevant figure for Experiment 4}
\label{fig:results:rq4:cm_detection_only}
\end{minipage}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{Images/05_experimental_results/RQ4/pr_curve.png}
    \caption{TODO: Replace with relevant figure for Experiment 4}
    \label{fig:results:rq4:pr_curve}
\end{figure}

\section{Experiment 5: System Efficiency and Real-World Validation}
\label{sec:experiments:results:5}

Assesses runtime performance, resource utilization, and stability under real-world sensor noise during physical deployment.

\newpage